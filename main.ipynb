{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install chromadb\n",
        "! pip install yt-dlp\n",
        "! pip install requests\n",
        "! pip install sentence_splitter"
      ],
      "metadata": {
        "id": "n-rzGf6lncbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "import os\n",
        "import time\n",
        "\n",
        "def file_exists(file_path):\n",
        "    return os.path.exists(file_path)\n",
        "\n",
        "def load_and_parse_json(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        json_data = json.load(file)\n",
        "        return json_data\n",
        "\n",
        "def get_timestamp():\n",
        "  return int(time.time_ns() / 1000)"
      ],
      "metadata": {
        "id": "a_7LaEkLB9sk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create project folder in your Drive and point to it here\n",
        "# create subfolders:\n",
        "# - videos\n",
        "# - transcriptions\n",
        "#\n",
        "BASE_DATA_LOCATION = \"drive/MyDrive/podcastopedia/YOUR_PROJECT_NAME\"\n",
        "CHROMA_API_IMPL=\"rest\"\n",
        "# deploy your Chroma and grab server URL\n",
        "# see https://docs.trychroma.com/deployment#simple-aws-deployment\n",
        "CHROMA_SERVER_HOST=\"\"\n",
        "CHROMA_SERVER_PORT=8000"
      ],
      "metadata": {
        "id": "lnWz4lp6B3tz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "#    Grab All videos for channel\n",
        "################################################################################\n",
        "# -> head to channel page - https://www.youtube.com/@MyFirstMillionPod/videos\n",
        "# -> make sure videos are sorted in desc order by publish date\n",
        "# -> grab all IDs with:\n",
        "#    let links = []; document.querySelectorAll(\"a[href^='/watch'].ytd-thumbnail\").forEach((el) => links.push(el.getAttribute(\"href\").replace(\"/watch?v=\", \"\").replace(/\\&pp=.+$/ig, \"\").replace(/\\&t=.+$/ig, \"\") ) ); console.log(JSON.stringify(links));\n",
        "# -> saved videos to videos.json (added to podcastopedia/mfm/videos.json)\n",
        "\n",
        "# list of IDs download\n",
        "videos = load_and_parse_json(f'{BASE_DATA_LOCATION}/videos.json')\n",
        "\n",
        "for video in videos:\n",
        "  file = f'{BASE_DATA_LOCATION}/videos/{video}.mp3'\n",
        "  if file_exists(file):\n",
        "    print(f\"video already downloaded {video}. skipping\")\n",
        "    continue\n",
        "\n",
        "  print(f\"gonna download {video} to {file}\")\n",
        "  !yt-dlp --force-overwrites -x --audio-format mp3 -o $file -- $video\n",
        "\n"
      ],
      "metadata": {
        "id": "uspx-STb8UYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "\n",
        "chroma = chromadb.HttpClient(host=CHROMA_SERVER_HOST, port=CHROMA_SERVER_PORT)\n",
        "\n",
        "transcripts_collection = chroma.get_or_create_collection(\"transcripts\")"
      ],
      "metadata": {
        "id": "AARnBut35G_1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcripts_collection.count()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fI3RFCWoVtFM",
        "outputId": "47207ea2-d122-447e-aa66-91af8acdb3bc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from sentence_splitter import split_text_into_sentences\n",
        "\n",
        "################################################################################\n",
        "#    Index transcriptions\n",
        "################################################################################\n",
        "\n",
        "transcriptions_dir = f\"{BASE_DATA_LOCATION}/transcriptions\"\n",
        "transcriptions = []\n",
        "\n",
        "# look for valid transcriptions + annotate each transcription\n",
        "# with id and source\n",
        "for file in os.listdir(transcriptions_dir):\n",
        "  if file.endswith(\".json\"):\n",
        "    id = file.split(\".\")[0]\n",
        "    source = \"youtube\"\n",
        "    d = load_and_parse_json(f\"{transcriptions_dir}/{file}\")\n",
        "    if \"utterances\" in d:\n",
        "      transcriptions.append({\n",
        "          \"id\": id,\n",
        "          \"source\": source,\n",
        "          \"transcription\": d\n",
        "      })\n",
        "\n",
        "try:\n",
        "  # process transcriptions\n",
        "  for i, t in enumerate(transcriptions):\n",
        "    id = t[\"id\"]\n",
        "    source = t[\"source\"]\n",
        "\n",
        "    print(f'>>>>>>> processing {id} {i+1}/{len(transcriptions)}')\n",
        "\n",
        "    for ts in t[\"transcription\"][\"utterances\"]:\n",
        "      sentences = split_text_into_sentences(text=ts[\"text\"], language='en')\n",
        "      transcripts_collection.add(\n",
        "        documents=sentences,\n",
        "        metadatas=list(map(lambda _: {\n",
        "          \"id\": id,\n",
        "          \"source\": source,\n",
        "          \"start\": ts[\"start\"],\n",
        "          \"end\": ts[\"end\"]\n",
        "        }, range(len(sentences)))),\n",
        "        ids=list(map(lambda _: f'{get_timestamp()}-{random.randint(0, 1000)}', range(len(sentences))))\n",
        "      )\n",
        "      print(\".\")\n",
        "\n",
        "except Exception as e:\n",
        "  print(f\"failed with {e}\")"
      ],
      "metadata": {
        "id": "QX-9kDOYsRx4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}